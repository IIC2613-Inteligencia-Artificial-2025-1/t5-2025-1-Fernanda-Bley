{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b4ba723c",
      "metadata": {
        "id": "b4ba723c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "from collections import Counter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "936e4a14",
      "metadata": {},
      "source": [
        "<style>\n",
        ".center {\n",
        "  display: block;\n",
        "  margin-left: auto;\n",
        "  margin-right: auto;\n",
        "  width: 50%;\n",
        "}\n",
        "</style>\n",
        "\n",
        "<img src=\"https://i.ibb.co/NbtsTwH/patito-goyito.png\" alt=\"Portada-T5-p1\" border=\"0\" class=\"center\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eaa77f1",
      "metadata": {
        "id": "5eaa77f1"
      },
      "source": [
        "### 1.3. Preguntas a responder\n",
        "\n",
        "* Autoencoders: investigue sobre los modelos autoencoders, mencione a grandes rasgos cómo es, su estructura y responda: ¿Por qué son útiles para comprimir y descomprimir datos? (extensión máxima 7 líneas)\n",
        "* Tokenización: investigue acerca de la tokenización de los textos. Describa brevemente el concepto y plantee un esquema de tokenización para sus datos. En este sentido, justifique el esquema que utilizaría, ya sea por palabras o por caracteres. (extensión máxima 7 líneas)\n",
        "* Funciones de pérdida: investigue sobre las funciones de pérdida y en particular sobre: Cross\n",
        "Entropy Loss. Explica cómo funciona y reflexiona sobre su utilidad en este contexto. (Extensión máxima 9 líneas).\n",
        "* Dropout: discuta sobre la utilidad de utilizar dropout en este contexto. Indique además en cuales capas de un autoencoder utilizaría dropout y en cuáles no. (Extensión máxima 10 líneas)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a126a259",
      "metadata": {
        "id": "a126a259"
      },
      "source": [
        "### 1.5.    Análisis del Modelo de Aprendizaje Profundo\n",
        "\n",
        "Hiperparámetros: Explique la elección de hiperparámetros que realizó; entiéndase por hiperparámetros elecciones como épocas de entrenamiento, longitud máxima de las frases, numero de capas, tamaño˜ de las capas, etc.\n",
        "Resultados: Presente una muestra de frases originales, vector de compresión Z y descompresiones hechas por el modelo, determine si su modelo tiende a fallar más en frases cortas o largas, y explique por qué razón podría ocurrir esto.\n",
        "\n",
        "Exactitud: Determine la cantidad de aciertos que tiene su modelo para predecir frases por medio de la cantidad de tokens en la posición correcta que el modelo entregó, obtenga al menos un 50% de acorace a nivel de token por posición. También calcule la cantidad de aciertos por frecuencia de palabras entre la frase original y la frase generada, sin importar el lugar en el que esté un token.\n",
        "\n",
        "Comente sobre sus resultados y qué pueden indicar los valores obtenidos sobre cómo el modelo predice las palabras. (extensión máxima 3-4 líneas)\n",
        "Errores de palabras: Comente sobre cuáles son las palabras que más errores presenta su modelo, y comente a qué podría deberse esto (frecuencia, ambigüedad, falta de datos, etc.). (extensión máxima 5 líneas)\n",
        "\n",
        "Compresor: Comente si este tipo de modelos es bueno para realizar compresión de texto. Con base en lo que investigo y determinó con sus resultados, decida si serviría o no para este propósito, ya sea con mejores ajustes, mayor capacidad de cómputo, entrenamiento, más memoria, etc. (extensión máxima 5-7 líneas)\n",
        "\n",
        "Seq2Seq: Investigue sobre las redes Seq2Seq, mencione diferencias y similitudes sobre el modelo que usted desarrolló y este tipo de redes. (extensión máxima 5-6 líneas)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60ed225f",
      "metadata": {
        "id": "60ed225f"
      },
      "source": [
        "El dataset que ocupe fue recuperado de Kaggle llamado [Quotes- 500k](https://www.kaggle.com/datasets/manann/quotes-500k/data) por Manan.\n",
        "\n",
        "Este tiene 500.000 frases por famosos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "04bc0457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "04bc0457",
        "outputId": "0169f034-d618-4df9-c2fe-15162f459a90"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "quotes"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c2133014-06f2-479a-9490-8a333ad0ba77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You've gotta dance like there's nobody watchin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You know you're in love when you can't fall as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A friend is someone who knows all about you an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Darkness cannot drive out darkness: only light...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2133014-06f2-479a-9490-8a333ad0ba77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2133014-06f2-479a-9490-8a333ad0ba77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2133014-06f2-479a-9490-8a333ad0ba77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e552b4a1-ca2c-4e66-b889-625c5da9f19a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e552b4a1-ca2c-4e66-b889-625c5da9f19a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e552b4a1-ca2c-4e66-b889-625c5da9f19a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               quote\n",
              "0  I'm selfish, impatient and a little insecure. ...\n",
              "1  You've gotta dance like there's nobody watchin...\n",
              "2  You know you're in love when you can't fall as...\n",
              "3  A friend is someone who knows all about you an...\n",
              "4  Darkness cannot drive out darkness: only light..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "quotes = pd.read_csv(\"quotes.csv\")\n",
        "\n",
        "quotes.drop(columns=[\"author\", \"category\"], inplace=True)\n",
        "\n",
        "quotes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e02b4ba",
      "metadata": {
        "id": "0e02b4ba"
      },
      "source": [
        "##### Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9cc05b33",
      "metadata": {
        "id": "9cc05b33"
      },
      "outputs": [],
      "source": [
        "# Limpiemos los textos\n",
        "\n",
        "def clean_text(text):\n",
        "    # Convertir a minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Eliminar acentos\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
        "\n",
        "    # Eliminar caracteres especiales y números\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Eliminar espacios extra\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29a1ec96",
      "metadata": {
        "id": "29a1ec96"
      },
      "outputs": [],
      "source": [
        "# Función para ver el numero de nulos y duplicados\n",
        "\n",
        "def check_nulls_and_duplicates(df):\n",
        "    nulls = df.isnull().sum()\n",
        "    duplicates = df.duplicated().sum()\n",
        "\n",
        "    return nulls, duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "db1adbe2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db1adbe2",
        "outputId": "60e2c108-bb05-4fe3-f2b3-56f7438415eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Buscando nulos y duplicados 🔍\n",
            "\n",
            "Hay 1 nulos en total\n",
            "\n",
            "Hay 5919 filas duplicadas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "quotes_cleaned = quotes.copy()\n",
        "\n",
        "# Verificar nulos y duplicados\n",
        "print(\"🔍 Buscando nulos y duplicados 🔍\\n\")\n",
        "nulls, duplicates = check_nulls_and_duplicates(quotes_cleaned)\n",
        "print(f\"Hay {nulls.sum()} nulos en total\\n\")\n",
        "print(f\"Hay {duplicates} filas duplicadas\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e7011f93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7011f93",
        "outputId": "c03efffa-aec7-4cee-ccd7-febe2167991b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Después de eliminar duplicados, hay 0 nulos en total\n",
            "\n",
            "Después de eliminar duplicados, hay 0 filas duplicadas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Vemos que hay 5919 filas duplicadas, las eliminamos\n",
        "quotes_cleaned.drop_duplicates(inplace=True)\n",
        "\n",
        "# Hay 1 valor nulo en el campo 'quote', lo eliminamos\n",
        "\n",
        "quotes_cleaned.dropna(subset=['quote'], inplace=True)\n",
        "\n",
        "# Verificamos nuevamente nulos y duplicados\n",
        "nulls, duplicates = check_nulls_and_duplicates(quotes_cleaned)\n",
        "print(f\"Después de eliminar duplicados, hay {nulls.sum()} nulos en total\\n\")\n",
        "print(f\"Después de eliminar duplicados, hay {duplicates} filas duplicadas\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "011e31bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "011e31bc",
        "outputId": "3f645548-fe6e-4e53-e50c-2db00c4e35e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔮 Normalizando los textos 🔮\n",
            "\n",
            "🆗 Textos normalizados 🆗\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Normalizar y limpiar los textos\n",
        "print(\"🔮 Normalizando los textos 🔮\\n\")\n",
        "quotes_cleaned['quote'] = quotes_cleaned['quote'].apply(clean_text)\n",
        "print(\"🆗 Textos normalizados 🆗\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "df050080",
      "metadata": {
        "id": "df050080"
      },
      "outputs": [],
      "source": [
        "# Supongamos que las frases están en la columna \"quote\"\n",
        "# Ajusta el nombre si tu columna se llama distinto\n",
        "max_len = 20\n",
        "\n",
        "# Filtrar frases por longitud\n",
        "filtered = quotes_cleaned[quotes_cleaned['quote'].apply(lambda x: 0 < len(x.split()) <= max_len)]\n",
        "\n",
        "# Si hay más de 300,000 después del filtro, tomar muestra aleatoria\n",
        "target_size = 300000\n",
        "if len(filtered) > target_size:\n",
        "    reduced_df = filtered.sample(n=target_size, random_state=42).reset_index(drop=True)\n",
        "else:\n",
        "    reduced_df = filtered.reset_index(drop=True)\n",
        "\n",
        "reduced_dataset = reduced_df['quote'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4V1Ul-xR5bv3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V1Ul-xR5bv3",
        "outputId": "64766966-d039-49bb-e2d6-547c6f60d8c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['you know youre in love when you cant fall asleep because reality is finally better than your dreams',\n",
              " 'a friend is someone who knows all about you and still loves you',\n",
              " 'darkness cannot drive out darkness only light can do that hate cannot drive out hate only love can do that',\n",
              " 'we accept the love we think we deserve',\n",
              " 'it is better to be hated for what you are than to be loved for what you are not']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reduced_dataset[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LFHXwZ016Mfi",
      "metadata": {
        "id": "LFHXwZ016Mfi"
      },
      "source": [
        "### Creamos los tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "yB_6GHNo8dUl",
      "metadata": {
        "id": "yB_6GHNo8dUl"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<UNK>\", filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(reduced_dataset)\n",
        "\n",
        "min_freq = 5\n",
        "filtered_words = {word: count for word, count in tokenizer.word_counts.items() if count >= min_freq}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "yyM-nuG0ANTB",
      "metadata": {
        "id": "yyM-nuG0ANTB"
      },
      "outputs": [],
      "source": [
        "tokenizer.word_index = {word: idx + 1 for idx, word in enumerate(filtered_words)}  # +1 por el padding\n",
        "tokenizer.word_index[\"<UNK>\"] = len(tokenizer.word_index) + 1\n",
        "tokenizer.index_word = {idx: word for word, idx in tokenizer.word_index.items()}\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 por <PAD>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b5_n51Ii_igP",
      "metadata": {
        "id": "b5_n51Ii_igP"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(reduced_dataset)\n",
        "padded = pad_sequences(sequences, maxlen=20, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "-miuxPie_0Mo",
      "metadata": {
        "id": "-miuxPie_0Mo"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "X_train, X_test = train_test_split(padded, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = np.expand_dims(X_train, -1)\n",
        "y_test = np.expand_dims(X_test, -1)\n",
        "\n",
        "y_train = y_train.squeeze(-1)  # Ahora será (num_samples, max_len)\n",
        "y_test = y_test.squeeze(-1)    # idem para validación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "xyLYvEs3Z4zZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyLYvEs3Z4zZ",
        "outputId": "7d80a63f-60ff-4792-d295-a7c37bd5086f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((171908, 20), (42978, 20), (171908, 20), (42978, 20))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fJ82_b2FT6I_",
      "metadata": {
        "id": "fJ82_b2FT6I_"
      },
      "outputs": [],
      "source": [
        "max_len = X_train.shape[1]\n",
        "\n",
        "# Preparar y_train desplazado (target = siguiente token)\n",
        "y_train_shifted = np.zeros_like(X_train)\n",
        "y_train_shifted[:, :-1] = X_train[:, 1:]\n",
        "y_train_shifted[:, -1] = 0  # padding al final\n",
        "\n",
        "y_test_shifted = np.zeros_like(X_test)\n",
        "y_test_shifted[:, :-1] = X_test[:, 1:]\n",
        "y_test_shifted[:, -1] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "XnRPgj5hA5JI",
      "metadata": {
        "id": "XnRPgj5hA5JI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Asegurar vocab_size\n",
        "vocab_size = max(X_train.max(), y_train_shifted.max()) + 1\n",
        "\n",
        "# Modelo simple seq2seq\n",
        "inputs = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=vocab_size, output_dim=32)(inputs)\n",
        "x = GRU(64, return_sequences=True)(x)\n",
        "outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Q4hZxVygdDRz",
      "metadata": {
        "id": "Q4hZxVygdDRz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Recuperado de StackOverflow: https://stackoverflow.com/questions/53500047/stop-training-in-keras-when-accuracy-is-already-1-0\n",
        "\n",
        "class TerminateOnBaseline(Callback):\n",
        "    \"\"\"Callback that terminates training when either acc or val_acc reaches a specified baseline\n",
        "    \"\"\"\n",
        "    def __init__(self, threshold=0.6):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        acc = logs.get(\"accuracy\")\n",
        "        if acc is not None and acc >= self.threshold:\n",
        "            print(f\"\\n✅ Accuracy alcanzó {acc:.2%}, deteniendo entrenamiento.\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "o7ueEq2TTY9U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7ueEq2TTY9U",
        "outputId": "e0c79d6e-5990-41af-8ddb-f03ccc29ea09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m10742/10745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6919 - loss: 2.3520\n",
            "✅ Accuracy alcanzó 85.20%, deteniendo entrenamiento.\n",
            "\u001b[1m10745/10745\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 18ms/step - accuracy: 0.6920 - loss: 2.3516\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cf743239c10>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Esto se demora 3 minutos a 38 segundos\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    .shuffle(buffer_size=1000)\n",
        "    .batch(16)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "stop_callback = TerminateOnBaseline(threshold=0.60)\n",
        "\n",
        "model.fit(train_ds, epochs=5, callbacks=[stop_callback])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "Ieyuce0GlyvO",
      "metadata": {
        "id": "Ieyuce0GlyvO"
      },
      "outputs": [],
      "source": [
        "# Este proceso se demora casi 3 minutos\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64\n",
        "predictions = []\n",
        "\n",
        "for i in range(0, len(X_test), batch_size):\n",
        "    x_batch = X_test[i:i+batch_size]\n",
        "    y_batch_pred = model.predict(x_batch, verbose=0)\n",
        "\n",
        "    # Tomar solo los índices de clase más probables\n",
        "    y_batch_class = np.argmax(y_batch_pred, axis=-1)\n",
        "\n",
        "    predictions.append(y_batch_class)\n",
        "\n",
        "# Unir todos los batches predichos en un solo array\n",
        "y_pred = np.vstack(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TRta3bLXoweP",
      "metadata": {
        "id": "TRta3bLXoweP"
      },
      "source": [
        "### Exactitud: Determine la cantidad de aciertos que tiene su modelo por nivel de token por posición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "BiFzNUyajeLv",
      "metadata": {
        "id": "BiFzNUyajeLv"
      },
      "outputs": [],
      "source": [
        "def frequency_accuracy(y_true, y_pred):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for true_seq, pred_seq in zip(y_true, y_pred):\n",
        "        true_counts = Counter(true_seq)\n",
        "        pred_counts = Counter(pred_seq)\n",
        "        matches = sum(min(true_counts[token], pred_counts[token]) for token in true_counts)\n",
        "        total += len(true_seq)\n",
        "        correct += matches\n",
        "    return 100 * correct / total\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    # Calcular la precisión\n",
        "    correct = np.sum(y_true == y_pred)\n",
        "    total = np.prod(y_true.shape)\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "Bvpy2uNFjtn3",
      "metadata": {
        "id": "Bvpy2uNFjtn3"
      },
      "outputs": [],
      "source": [
        "# Convertir a tokens predichos por posición\n",
        "y_pred_tokens = np.argmax(y_pred, axis=-1)  # (batch, max_len)\n",
        "\n",
        "freq_acc = frequency_accuracy(y_test, y_pred)\n",
        "test_accuracy = accuracy(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "hKtfj6qukOfZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKtfj6qukOfZ",
        "outputId": "ddeae9f9-4684-4cf1-9f23-7ef8cf5e293c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El accuracy por la cantidad de aciertos que tiene su modelo\n",
            "por nivel de token por posición es del 97.39%\n"
          ]
        }
      ],
      "source": [
        "print(f\"El accuracy por la cantidad de aciertos que tiene su modelo\\npor nivel de token por posición es del {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jBqC1-Tso5Hf",
      "metadata": {
        "id": "jBqC1-Tso5Hf"
      },
      "source": [
        "#### También calcule la cantidad de aciertos por frecuencia de palabras entre la frase original y la frase generada, sin importar el lugar en el que esté un token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "qvkePz_AlYrf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvkePz_AlYrf",
        "outputId": "5fab34ac-bb5e-4ee4-95c7-25f0e5d30786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El accuracy por la cantidad de aciertos que tiene su modelo\n",
            "por nivel de token independiente de la posición es del 97.39%\n"
          ]
        }
      ],
      "source": [
        "print(f\"El accuracy por la cantidad de aciertos que tiene su modelo\\npor nivel de token independiente de la posición es del {freq_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xEx69Mig0NLQ",
      "metadata": {
        "id": "xEx69Mig0NLQ"
      },
      "source": [
        "Comente sobre sus resultados y qué pueden indicar los valores obtenidos sobre cómo el modelo\n",
        "predice las palabras. (extensión máxima 3-4 lı́neas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W4cp3xEh0SJQ",
      "metadata": {
        "id": "W4cp3xEh0SJQ"
      },
      "source": [
        "Errores de palabras: Comente sobre cuáles son las palabras que más errores presenta su modelo, y\n",
        "comente a qué podrı́a deberse esto (frecuencia, ambigüedad, falta de datos, etc.). (extensión máxima\n",
        "5 lı́neas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "OLlpQaJ80YB-",
      "metadata": {
        "id": "OLlpQaJ80YB-"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def errores_por_token(y_true, y_pred):\n",
        "    errores = Counter()\n",
        "    for true_seq, pred_seq in zip(y_true, y_pred):\n",
        "        for t, p in zip(true_seq, pred_seq):\n",
        "            if t != p:\n",
        "                errores[t] += 1\n",
        "    return errores.most_common()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "szV97s3e0lFl",
      "metadata": {
        "id": "szV97s3e0lFl"
      },
      "outputs": [],
      "source": [
        "errores = errores_por_token(y_test, y_pred)\n",
        "top_ten = [(tokenizer.index_word.get(int(token_id), \"[UNK]\"), count) for token_id, count in errores[:10]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "dpa9VdrS49VS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpa9VdrS49VS",
        "outputId": "916b0e0e-a252-4751-cdd9-5c4ec6edd2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "╒══════╤═════════════╤═══════════╕\n",
            "│  N°  │   Palabra   │  Errores  │\n",
            "╞══════╪═════════════╪═══════════╡\n",
            "│  1   │  immortal   │    24     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  2   │   status    │    22     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  3   │   refuses   │    20     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  4   │    tends    │    18     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  5   │    ball     │    18     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  6   │ challenged  │    17     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  7   │     due     │    16     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  8   │   shield    │    16     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  9   │   paradox   │    16     │\n",
            "├──────┼─────────────┼───────────┤\n",
            "│  10  │ immediately │    15     │\n",
            "╘══════╧═════════════╧═══════════╛\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "tabla = [(i+1, palabra, count) for i, (palabra, count) in enumerate(top_ten)]\n",
        "\n",
        "# Mostrar tabla\n",
        "print(tabulate(tabla, headers=[\"N°\", \"Palabra\", \"Errores\"], tablefmt=\"fancy_grid\", colalign=(\"center\", \"center\", \"center\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GqX3ToYv87Gu",
      "metadata": {
        "id": "GqX3ToYv87Gu"
      },
      "source": [
        "Segun el [Corpus of Contemporary American English](https://www.english-corpora.org/coca/)\n",
        "\n",
        "* immortal está en la posición\n",
        "\\# 9885\n",
        "\n",
        "* status está en la posición\n",
        "\\# 1274\n",
        "* refuse está en la posición\n",
        "\\# 1339\n",
        "* tends está en la posición\n",
        "\\# 1182\n",
        "* ball está en la posición\n",
        "\\# 877\n",
        "* challenged está en la posición\n",
        "\\# 26810\n",
        "* due está en la posición\n",
        "\\# 1277\n",
        "* shield está en la posición\n",
        "\\# 4562\n",
        "* paradox está en la posición\n",
        "\\# 7447\n",
        "* immediately está en la posición\n",
        "\\# 1210\n",
        "\n",
        "Con eto puedo concluir, que tiene sentido que no haya identificado bien estas palbras, ya que no son tan comunes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BpuUjmN80VzM",
      "metadata": {
        "id": "BpuUjmN80VzM"
      },
      "source": [
        "\n",
        "Compresor: Comente si este tipo de modelos es bueno para realizar compresión de texto. Con base\n",
        "en lo que investigo y determinó con sus resultados, decida si servirı́a o no para este propósito, ya\n",
        "sea con mejores ajustes, mayor capacidad de cómputo, entrenamiento, más memoria, etc. (extensión\n",
        "máxima 5-7 lı́neas)\n",
        "Seq2Seq: Investigue sobre las redes Seq2Seq, mencione diferencias y similitudes sobre el modelo\n",
        "que usted desarrolló y este tipo de redes. (extensión máxima 5-6 lı́neas)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
